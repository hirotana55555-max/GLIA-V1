{
  "_GLIA_Constitutional_Core": {
    "purpose": "ABSOLUTE OUTPUT PROTOCOL for LLMs. Prevents hallucinations by structural enforcement. This file is static; project state is dynamic and MUST be fetched via sync-project.sh.",
    
    "absolute_truth_foundation": {
      "non_negotiable_step": "BEFORE any GLIA-related output, execute sync-project.sh and read SPEC_SYNC.md to get current facts:",
      "command": "cd /home/els/Antigravity/GLIA-V1/SPEC/script && ./sync-project.sh",
      "proof_requirement": "In your FIRST response, quote SPEC_SYNC.md to prove fresh state.",
      "deep_analysis_requirement": "For code changes, analyze affected files and dependencies using SPEC_SYNC.md AND SPEC_PACKAGE.txt (generate if needed)."
    },
    
    "output_integrity_framework": {
      "language_optimization": {
        "user_language_mirroring": "Respond to the user in their language (e.g., Japanese) for explanations, analysis, and discussions.",
        "technical_language_preservation": "Maintain English for: code blocks, JSON structures, terminal commands, file paths, protocol names, and citation formats.",
        "hybrid_output_strategy": "Seamlessly blend natural language explanations with preserved technical English elements.",
        "rationale": "Minimize the communication cost for non-engineer Japanese language users while ensuring machine-readability of technical output."
      },
      
      "context_aware_output": {
        "discussion_mode": "For analysis, reasoning, planning: use natural conversation in user's language with embedded citations.",
        "execution_mode": "For code, commands, structured data: use clear blocks in English optimized for copy-paste.",
        "detection": "Judge context from user request: questions → discussion, implementation tasks → execution."
      },
      
      "citation_lifecycle": {
        "source_priority": "Primary: SPEC_SYNC.md (current state). Secondary: SPEC_PACKAGE.txt (detailed specs).",
        "integration_rule": "Every factual claim MUST have citation. In discussion: weave naturally in user's language. In execution: use [CITATION:file:section:quote] in English.",
        "verification": "User MUST be able to trace any claim to SPEC files. LLM self-checks before finalizing."
      },
      
      "web_llm_optimization": {
        "primary_directive": "For web LLM, optimize EVERY output for easy copy-paste to terminal.",
        "formatting_rules": [
          "Commands: one per line, no markdown blocks, no line breaks within commands.",
          "JSON: minified single line when possible, or clear indentation for readability.",
          "File paths: full paths for clarity, relative paths for brevity in context."
        ],
        "protocol_hierarchy": "If SPEC/ForLLM/COPY_PASTE_PROTOCOL.json exists, apply its rules AFTER this constitution."
      }
    },
    
    "zero_tolerance_rules": {
      "rule_1": "NEVER output GLIA analysis without FIRST syncing and quoting SPEC_SYNC.md. (根拠必須)",
      "rule_2": "NEVER assume project state. ALWAYS fetch fresh state via sync-project.sh. (動的事実)",
      "rule_3": "ALL code experiments in TEMP/YYYYMMDD_taskname/. Never modify production directly. (安全隔離)",
      "rule_4": "NEVER propose edits to SPEC/ (SPEC_DOC, script). Only hiroshi or Architect LLM may modify. (SPEC保護)",
      "rule_5": "When proposing code changes, MUST analyze affected files and dependencies using SPEC_SYNC.md and SPEC_PACKAGE.txt. (精緻分析)",
      "rule_6": "For web LLM output: ALWAYS optimize for easy copy-paste. Follow COPY_PASTE_PROTOCOL.json if exists. (ユーザー体験)",
      "rule_7": "Preserve language boundaries: Explanations in user's language, technical elements in English. (言語最適化)",
      "rule_8": "When uncertain: output [PROTOCOL_VIOLATION_RISK] and ask hiroshi. (安全確認)"
    },
    
    "constitutional_discipline": {
      "irrevocable_core": "Only hiroshi changes this file. Core principles are absolute.",
      "dynamic_adaptation": "LLM adapts to project changes via sync-project.sh outputs.",
      "pragmatic_evolution": "Rules evolve based on actual user experience, especially web LLM usability."
    }
  }
}